# 关于在yolo框架中更换主干网络的实操
## 本实操记录均基于VOC数据集，如果一切顺利的话
## 可能更换的网络：
resnet50，mobilenet small/large

## 如果训练机还有多余的空间，将重新在已有网络上多次调参对比数据

## 3.10 12：00
正在向训练机中下载VOC数据集

## 3.11 17:17
经过约两天的训练机训练，满载的情况下训练机需要约48小时训练约65轮，时间效率极慢。对比训练还是由coco128完成，除非在此基础上找到可以平衡的数据集

## 3.11 17：23
玩就玩个大的，参照tph-yolo论文，将一堆的tricks缝合到yolo里面，属实是buaa缝合怪，论文参考上述，我直接谈谈我用到了什么缝合的操作

我并没有用数据增强模块，但如果是使用coco128 dataset，我会选择photometic或者是geometic，这两个分别对图片进行饱和度，通道值，图片大小和图片基础元素进行调整，在我前面的summary中已经给出。但是，BUAA的作者在代码中给出了mixup，cutmix和cutmix的beyond版本，mosaic。这几个分为样本的随机加权求和，和随机裁剪覆盖的操作，属实缝合怪。这操作无疑可以丰富object的background。

之所以开这玩意，是因为yolo具有良好的网络替换性，这玩意不仅backbone可以换，head和neck都可以换，操作不唯一，也难怪会有这么多缝合怪论文出现。

我目前的操作是使用魔改的yolo框架，对比了common能或多或少知道作者想在框架里面加多少tricks，目前源码阅读下来发现了mlp，更改了yolo的feature map，其中细分了划分和还原，在源码发现了旧版的sppf函数和一个未知的aspp函数，也许是5.0版本改的，还没有适配新的6.1 realease。原版框架和魔改都加了注意力机制，其中魔改加了多层感知器。总体大的common框架并没有改多少，只是增加了可能会在魔改中调用的api和函数而已。奇怪的是，基于yolov5s魔改的是最新的6.0版本，可能是common没有及时查看。看起来作者的意思只是想替换一下yolo里面的卷积块，添加进去的是transformer encoder，可能是觉得可以获得更多的全局信息吧，因为我还没训练，也没法根据模型进行detect，暂且这么认为作者的意图。tph的意思是transformer prediction head，作者目的是想让transformer这个block形成tph和主干网络，因为到网络的末端时候，特征图的分辨率已经非常低了，在早期放大图像分辨率可以去除早期的一些tph模块，加快训练进度。同样的，注意力模块采用了CBAM，这里留空，我先去看看CBAM是个什么东西。

