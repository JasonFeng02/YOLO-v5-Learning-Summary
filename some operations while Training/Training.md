# 对于调参的操作及我个人的一些想法

## 本文基于`COCO128`数据集

### 早期
对于训练的早期处理，个人认为需要加上pretrain参数进行数据空间的确定，所以在早期的训练设置了10个epoch作为预训练轮，
其中有3个epoch是作为预训练的热身轮，以大bs，大lr作为快速梯度下降的基础，在这里我设置了workers=2，epoch=54，
优化器在第四轮epoch的时候介入，调低bs和lr，以更好降低梯度。

训练机卡的一，本来想截图放个loss的图，效果非常好，但是真的卡的一，edge寄了，怕不是散热不行

3.6 23：03 训练机又死机了，可能真的是PCIe速率有问题，这次没有数据保存下来，最后一次的log发现gpu0和1在未训练时就达到满载

### 中期
中期使用100轮epoch，hyperp使用了中等的速率，增大workers，将线程设为4，以降低bs大小，此阶段的bs将不大于16，大于4，
lr = 0.01并根据优化器持续降低，此阶段的pretrain参数使用早期训练的best.pt，这个时候是为了让模型在方向和精度上都
推进，整体的数据空间采用前期的方向，所以使用不太大的bs和lr进行继承，超参数使用了中等的hyper参数，避免过于激进或过于保守
这个阶段训练的best.pt将作为末期的pretrain


### 末期
后期使用500轮epoch，加大epoch是因为希望patience机制介入，在即将过拟合的时候停止训练，达到梯度的整体最低，此时使用最严格的
hyperp，一开始使用的是finetune的hyperp，lr初始值就设为0.0032，lf最大为0.14，将模型向更加精细化的方向推进，bs最大设为4，优化器根据epoch完成度降低bs大小，
workers设为6，用小bs和小lr使得模型在保持已有的方向和数据空间的情况下在精度上推进，但是情况不乐观，后面的loss已经开始上下波动，没有很好的下降曲线，
后改成更小的lf，在末期达到更小的lr，同时调小workers，epoch数量不变.但是结果仍然不理想

3.7，公版titan可能显存出问题了，连接不上，过两天再看看吧，现在是非公顶支撑着锻炼。

更新于3.7 22：55，在100轮的best.pt的作为pretrain的基础上，将lr降低至1e-6，bs仍然维持为4，workers因为对性能衰减没有影响，我决定将workers堆到机器极限，
最终的workers设为单卡为4，否则会内存溢出。
lf根据曲线目前设置了0.0001，最后lr将在1e-10结束。

## 关于训练疑点
在训练时如果使用了wandb，并且用edge查看wandb的loss参数，机器会非常卡，cpu占用会急剧上升，初步认为yolo在引用wandb的时候没有注意内存泄漏，进程没有closed

## 一些finetune中的个人看法
的确，在使用更小的lr之后，val——loss的表现确实很好，在逐渐下降的时候进行小规模波动，一段时间后整体全部不下降并伴随小幅度的波动，这代表着已经即将达到最小梯度的状态，即当前最佳，trainloss是用于查看自己代码和hyperp的效率，trainloss才是验证模型拟合度的指标。这个时候，valloss波动大，说明bs很小，但lr不够小。如果确实lr已经非常小，则可以适当增加微量的bs，通常+1.
documents也提到，越大的bs越稳定，原文的概念是，当bs越大，越接近整体梯度下降，越大的bs每次更新的方向和大小越正确。越小的bs越不稳定，也称之为采样不稳定，这时应该给这个不确定的更新意见付出比较小的effort去更新方向，即调小lr。此举可以让跨iter的意见保留。从数据空间上理解，则为越小的bs距离当前空间的最小值越近，所以整体的目的是以尽量小的bs，但是又不能让他陷入局部最小。所以错误的更新意见（即小bs）要搭配尽量小的lr。不能让其脱离大bs迭代器到达的最小状态。yolo的documents的方向大抵是为了防止使用者使用极小的bs训练迭代上千次，所以在documents中提出使用尽可能大的bs，因为默认给出的yolo pretrain参数已经包含了大部分目标检测的细节，实际上确实可以达到不错的效果，但是如果你拥有一个非常好的数据集，比如coco，比如imagenet，使用上述的方式进行调参，慢慢使参数符合下降趋势，重新调节预训练部分学到的细节，会使模型的val loss拥有比常规训练出来的val loss更加低的数值，准确度会更高。
